{"cells":[{"cell_type":"markdown","metadata":{"id":"hGrim1IBxhl_"},"source":["# Pneumonia Final Project Playground\n","\n","> *This is a testing environment for assessing the different models*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tmm_GHj-xnyX"},"outputs":[],"source":["!pip install gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IVPs5ADxp6a"},"outputs":[],"source":["import os\n","\n","from keras.saving import load_model\n","from pathlib import Path\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","import zipfile\n","\n","from google.colab import files as colabfiles\n","\n","MODELS_DIR = r'/content/old_models'\n","SIZE = 150\n","\n","def download_file(file_id, destination):\n","  !gdown --id $file_id -O $destination\n","\n","\n","def download_model(file_id, destination):\n","  temp_zip = f'{destination}.zip'\n","  download_file(file_id, temp_zip)\n","\n","  with zipfile.ZipFile(temp_zip, 'r') as zip_ref:\n","    zip_ref.extractall(destination)\n","\n","  os.remove(temp_zip)\n","\n","\n","def process_image_for_prediction(size = SIZE):\n","  image_string = list(colabfiles.upload().values())[0]\n","  image = tf.io.decode_image(image_string, channels=1)\n","  image = tf.image.resize(image, (size, size))\n","  image_tensor = tf.expand_dims(image, axis=0)\n","  binary_array = np.asarray(image_tensor)\n","  binary_array.reshape(1,-1)\n","  binary_array = binary_array / 255\n","\n","  return binary_array\n","\n","\n","MODEL_1 = 'MODEL_1'\n","MODEL_2 = 'MODEL_2'\n","EMBEDDING_MODEL_1 = 'EMBEDDING_MODEL_1'\n","EMBEDDING_MODEL_2 = 'EMBEDDING_MODEL_2'\n","KNN_1 = 'KNN_1'\n","KNN_2 = 'KNN_2'\n","MODEL_4 = 'MODEL_4'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8PkL9NzPKYN"},"outputs":[],"source":["download_model('1KuDRHUAqib308xn-ST76dh8XquvmAQ6R', MODEL_1)\n","download_model('1-S2tt6xIZGbQfPsygvneeUOnI7HozKik', MODEL_2)\n","download_model('1SQ-L3vze24J7DsqYHuWGMLC_TAu4Ls9G', EMBEDDING_MODEL_1)\n","download_model('18TEWxyvnbQGXXZuRSuWM8JXjp84z2JFf', EMBEDDING_MODEL_2)\n","download_file('1yys_C3ljg1WmCfTdiyWmiZ71EfJ4TjT-', KNN_1)\n","download_file('1E6az9MymUQk45cYdBBEU0KrSGjmWJFCi', KNN_2)\n","download_model('1_sNV928uSerQtDv74hx4zz9Q_j_p5G9N', MODEL_4)"]},{"cell_type":"markdown","metadata":{"id":"RQPwobCMPkhl"},"source":["# Task 1 - Playground\n","In this assignment, we were tasked with constructing a neural network designed to differentiate between images depicting lungs afflicted with pneumonia and those that are not."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNeKhozySAbM"},"outputs":[],"source":["TASK_1_CLASSES = ['NORMAL', 'PNEUMONIA']\n","model_1 = load_model(MODEL_1)\n","\n","image = process_image_for_prediction()\n","prediction = int(np.round(model_1.predict(image)).flatten()[0])\n","print(TASK_1_CLASSES[prediction])"]},{"cell_type":"markdown","metadata":{"id":"2bRopqmgPvlG"},"source":["# Task 2 - Playground\n","This task resembles the previous one, but it requires distinguishing between two types of pneumonia: viral and bacterial."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qW3Fi1NQTm7C"},"outputs":[],"source":["TASK_2_CLASSES = ['BACTERIA', 'NORMAL', 'VIRUS']\n","model_2 = load_model(MODEL_2)\n","\n","image = process_image_for_prediction()\n","prediction = np.argmax(model_2.predict(image).flatten())\n","print(TASK_2_CLASSES[prediction])"]},{"cell_type":"markdown","metadata":{"id":"5h1TQ50nP2tE"},"source":["# Task 3 - Playground\n","Here, we aim to employ the KNN strategy to facilitate the classification of new images by leveraging both the first and second neural networks developed in the previous tasks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbIQdlCdgiZv"},"outputs":[],"source":["TASK_3_1_CLASSES = ['NORMAL', 'PNEUMONIA']\n","embedding_model_1 = load_model(EMBEDDING_MODEL_1)\n","\n","with open(KNN_1, 'rb') as f:\n","    knn1 = pickle.load(f)\n","    image = process_image_for_prediction()\n","    embedding_prediction = embedding_model_1.predict(image)\n","    prediction = knn1.predict(embedding_prediction)[0]\n","\n","print(TASK_3_1_CLASSES[prediction])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53X23dGapsDz"},"outputs":[],"source":["TASK_3_2_CLASSES = ['BACTERIA', 'NORMAL', 'VIRUS']\n","embedding_model_2 = load_model(EMBEDDING_MODEL_2)\n","\n","with open(KNN_2, 'rb') as f:\n","    knn2 = pickle.load(f)\n","    image = process_image_for_prediction()\n","    embedding_prediction = embedding_model_2.predict(image)\n","    prediction = knn2.predict(embedding_prediction)[0]\n","\n","print(TASK_3_2_CLASSES[prediction])"]},{"cell_type":"markdown","metadata":{"id":"m0LytSUWQELC"},"source":["# Task 4 - Playground\n","In this task, we operate under the assumption that we only possess \"normal\" lung scans. Our objective is to identify pneumonia scans utilizing the anomaly detection method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVB-I2HxqFuG"},"outputs":[],"source":["THRESHOLD = 0.02\n","def detect_anomaly(img_array, model, threshold):\n","    reconstructed_img = model.predict(img_array)\n","    loss = np.mean(np.abs(reconstructed_img - img_array))\n","    print(loss)\n","    if loss > threshold:\n","        print(\"PNEUMONIA\")\n","    else:\n","        print(\"NORMAL\")\n","\n","img = process_image_for_prediction(size=256)\n","autoencoder = load_model(MODEL_4)\n","detect_anomaly(img, autoencoder, THRESHOLD)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN2jvBQOAOOQtMRPP4R5TTY","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
